{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with epoch 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "\n",
    "def load_train_data(n):\n",
    "    with open('data_batch_'+ str(n), 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    features = batch['data']\n",
    "    Target = batch['labels']\n",
    "    return features, Target\n",
    "\n",
    "\n",
    "batch_1, Target_1 = load_train_data(1)\n",
    "batch_2, Target_2 = load_train_data(2)\n",
    "batch_3, Target_3 = load_train_data(3)\n",
    "batch_4, Target_4 = load_train_data(4)\n",
    "batch_5, Target_5 = load_train_data(5)\n",
    "\n",
    "\n",
    "with open('test_batch', 'rb') as file:\n",
    "    batch = pickle.load(file, encoding='latin1')\n",
    "X_test = batch['data']\n",
    "y_test = batch['labels']\n",
    "\n",
    "\n",
    "X_train = np.append(batch_1, batch_2,axis=0)\n",
    "X_train = np.append(X_train, batch_3,axis=0)\n",
    "X_train = np.append(X_train, batch_4,axis=0)\n",
    "X_train = np.append(X_train, batch_5,axis=0)\n",
    "y_train = np.append(Target_1, Target_2,axis=0)\n",
    "y_train = np.append(y_train, Target_3,axis=0)\n",
    "y_train = np.append(y_train, Target_4,axis=0)\n",
    "y_train = np.append(y_train, Target_5,axis=0)\n",
    "X_train = X_train.reshape((len(X_train), 3, 32, 32)).transpose(0,2,3,1)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "X_test = X_test.reshape((len(X_test), 3, 32, 32)).transpose(0,2,3,1)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test= X_test.astype('float32')\n",
    "X_train= X_train / 255.0\n",
    "X_test= X_test/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 232,970\n",
      "Trainable params: 232,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model19 = Sequential()\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same', input_shape=(32, 32, 3)))\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same'))\n",
    "model19.add(MaxPooling2D((2, 2)))\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same'))\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same'))\n",
    "model19.add(MaxPooling2D((2, 2)))\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same'))\n",
    "model19.add(MaxPooling2D((2, 2)))\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same'))\n",
    "model19.add(MaxPooling2D((2, 2)))\n",
    "model19.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_normal',padding = 'same'))\n",
    "model19.add(MaxPooling2D((2, 2)))\n",
    "model19.add(Flatten())\n",
    "model19.add(Dense(128, activation='relu'))\n",
    "model19.add(Dropout(rate = 0.7))\n",
    "model19.add(Dense(10, activation='softmax'))\n",
    "model19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dhanajayan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 487s 10ms/step - loss: 1.7711 - acc: 0.3381\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 528s 11ms/step - loss: 1.2558 - acc: 0.5572\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 533s 11ms/step - loss: 1.0379 - acc: 0.6443\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 525s 10ms/step - loss: 0.9026 - acc: 0.6924\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 510s 10ms/step - loss: 0.8114 - acc: 0.7286\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 514s 10ms/step - loss: 0.7426 - acc: 0.7535\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 504s 10ms/step - loss: 0.6898 - acc: 0.7702\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 451s 9ms/step - loss: 0.6388 - acc: 0.7888\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 446s 9ms/step - loss: 0.5992 - acc: 0.8021\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 448s 9ms/step - loss: 0.5674 - acc: 0.8124\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 442s 9ms/step - loss: 0.5353 - acc: 0.8244\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 440s 9ms/step - loss: 0.5083 - acc: 0.8347\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 0.4904 - acc: 0.8400\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 371s 7ms/step - loss: 0.4711 - acc: 0.8477\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 401s 8ms/step - loss: 0.4487 - acc: 0.8546\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 431s 9ms/step - loss: 0.4299 - acc: 0.8597\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 398s 8ms/step - loss: 0.4163 - acc: 0.8654\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 408s 8ms/step - loss: 0.3986 - acc: 0.8698\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 375s 8ms/step - loss: 0.3987 - acc: 0.8715\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 387s 8ms/step - loss: 0.3851 - acc: 0.8757\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 392s 8ms/step - loss: 0.3668 - acc: 0.8824\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.3556 - acc: 0.8859\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 360s 7ms/step - loss: 0.3514 - acc: 0.8867\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.3452 - acc: 0.8889\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.3501 - acc: 0.8872\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 346s 7ms/step - loss: 0.3260 - acc: 0.8944\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.3301 - acc: 0.8953\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.3200 - acc: 0.8990\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 388s 8ms/step - loss: 0.3328 - acc: 0.8961\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 395s 8ms/step - loss: 0.3244 - acc: 0.8999\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.3117 - acc: 0.9039 1s - loss: 0.3111 - ac\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.3102 - acc: 0.9036\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 0.3171 - acc: 0.9021\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 397s 8ms/step - loss: 0.2923 - acc: 0.9090\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 416s 8ms/step - loss: 0.2947 - acc: 0.9093\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 438s 9ms/step - loss: 0.3033 - acc: 0.9073\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 445s 9ms/step - loss: 0.3046 - acc: 0.9075\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 458s 9ms/step - loss: 0.2721 - acc: 0.9152\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 458s 9ms/step - loss: 0.2853 - acc: 0.9142\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 445s 9ms/step - loss: 0.2748 - acc: 0.9156\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 467s 9ms/step - loss: 0.2896 - acc: 0.9121\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 467s 9ms/step - loss: 0.2819 - acc: 0.9156\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 467s 9ms/step - loss: 0.2972 - acc: 0.9114\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 468s 9ms/step - loss: 0.2739 - acc: 0.9171\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 468s 9ms/step - loss: 0.2697 - acc: 0.9208\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 468s 9ms/step - loss: 0.2841 - acc: 0.9160\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 468s 9ms/step - loss: 0.2674 - acc: 0.9201\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 464s 9ms/step - loss: 0.2898 - acc: 0.9144\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 462s 9ms/step - loss: 0.2810 - acc: 0.9186\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 453s 9ms/step - loss: 0.2733 - acc: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a226c61240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "model19.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model19.fit(X_train,y_train,epochs=epochs,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 32s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7638"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss,test_acc = model19.evaluate(X_test,y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model overfits the data with 50 epochs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. In the image classification model the following layers are used.\n",
    "  * Conv2D layer\n",
    "          \n",
    "          Keras Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel \n",
    "          that is wind with layers input which helps produce a tensor of outputs.\n",
    "\n",
    "          Kernel: In image processing kernel is a convolution matrix or masks which can be           used for blurring, sharpening, embossing, edge detection and more by doing a \n",
    "          convolution between a kernel and an image.\n",
    "          \n",
    "  * Maxpooling2D\n",
    "  \n",
    "          Calculate the maximum value for each patch of the feature map.\n",
    "  \n",
    "  * Flatten \n",
    "  \n",
    "          Flatten layer which prepares a vector for the fully connected layers or dense \n",
    "          layer.\n",
    "          \n",
    "  * Dropout layer\n",
    "  \n",
    "          Helps to reduce the overfitting.\n",
    "          \n",
    "  * Dense layer\n",
    "  \n",
    "          A dense layer represents a matrix vector multiplication.The values in the matrix           are the trainable parameters which get updated during backpropagation.\n",
    "  \n",
    "          \n",
    "\n",
    "In this models cross validation, data agumentation,batch normalization and hyperparameter tuning using sklearn are not used. \n",
    "\n",
    "Manually checked how  parameters are affecting the accuracy. \n",
    "\n",
    "In deeplearning models there are many parameters to tune .so monitoring every parameter is mandatory.\n",
    "\n",
    "To fix the following issues\n",
    " 1. Computation speed\n",
    " 2. overfitting and underfitting\n",
    " \n",
    "Need to understand the behaviour of the addition of the hidden layers and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
